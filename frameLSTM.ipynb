{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"frameLSTM","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPtPU/IhFTldwA2e2xSK/eu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ji4upfrXU5un"},"source":["from google.colab import drive\n","drive.mount('/gdrive/', force_remount=False)\n","!ls /gdrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTSUa2UvU8KG"},"source":["import os\n","\n","BASE_PATH = '/gdrive/My Drive/colab_files/framelstm/'\n","if not os.path.exists(BASE_PATH):\n","    os.makedirs(BASE_PATH)\n","\n","!pwd\n","!ls\n","!echo\n","os.chdir(BASE_PATH)\n","if not os.path.exists(BASE_PATH + 'MovingMNIST.py'):\n","    !wget https://raw.githubusercontent.com/tychovdo/MovingMNIST/master/MovingMNIST.py\n","!pwd\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3M7Qybnk-3HE"},"source":["import torch\n","import torch.nn as nn\n","\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import sys\n","sys.path.append(BASE_PATH)\n","import pt_util"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbUNcLJE--lR"},"source":["# basic code reference from https://stackabuse.com/time-series-prediction-using-lstm-with-pytorch-in-python/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4mZas_Bfb0w"},"source":["from MovingMNIST import MovingMNIST\n","\n","# MovingMNIST from http://www.cs.toronto.edu/~nitish/unsupervised_video/\n","# MovingMNIST dataset specifically from http://www.cs.toronto.edu/~nitish/unsup_video.pdf paper\n","# MovingMNIST code specifically from https://github.com/tychovdo/MovingMNIST\n","train_set = MovingMNIST(root='data/mnist', train=True, download=True)\n","test_set = MovingMNIST(root='data/mnist', train=False, download=True)\n","\n","batch_size = 1\n","mnist_seq_length = 10 # this is constant in the dataset, I think\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset=train_set,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","test_loader = torch.utils.data.DataLoader(\n","    dataset=test_set,\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","print('==>>> total training batch number: {}'.format(len(train_loader)))\n","print('==>>> total testing batch number: {}'.format(len(test_loader)))\n","\n","for seq, seq_target in train_loader:\n","    print('--- Sample tensor sizes... ---')\n","    print('Input:  ', seq.shape)\n","    print('Target: ', seq_target.shape)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-kprAFL_ei4"},"source":["class LSTM(nn.Module):\n","    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n","        super().__init__()\n","        self.hidden_layer_size = hidden_layer_size\n","        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n","        self.hidden_cell = (\n","            torch.zeros(1,1,self.hidden_layer_size),\n","            torch.zeros(1,1,self.hidden_layer_size)\n","        )\n","        self.linear = nn.Linear(hidden_layer_size, output_size)\n","\n","    def forward(self, input_seq):\n","        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n","        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n","        return predictions[-1:]\n","\n","    def loss(self, loss_function, prediction, labels):\n","        loss_val = loss_function(prediction, labels)\n","        return loss_val\n","\n","    def save_model(self, file_path, num_to_keep=1):\n","        pt_util.save(self, file_path, num_to_keep)\n","        \n","    def save_best_model(self, accuracy, file_path, num_to_keep=1):\n","        if self.accuracy == None or accuracy > self.accuracy:\n","            self.accuracy = accuracy\n","            self.save_model(file_path, num_to_keep)\n","\n","    def load_model(self, file_path):\n","        pt_util.restore(self, file_path)\n","\n","    def load_last_model(self, dir_path):\n","        return pt_util.restore_latest(self, dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGsAuLkyFk_T"},"source":["def train_model(data_size, epochs, start_save_path=None, end_save_path=None):\n","    # initialize some training meta variables\n","    training_print_interval = 4000\n","    epoch_print_interval = 1\n","\n","    # initialize the model we will be training!\n","    model = LSTM(input_size=data_size, output_size=data_size)\n","    if start_save_path is not None:\n","        model.load_model(start_save_path)\n","    loss_function = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    for i in range(epochs):\n","        # do one epoch of training\n","        model.train()\n","        train_losses = []\n","        for batch_idx, (seq, seq_target) in enumerate(train_loader):\n","            flat_seq = seq.permute(1,2,3,0).view(mnist_seq_length,-1).float()\n","            flat_seq_target = seq_target[:, 0, :, :].view(1,-1).float()\n","            # initialize batch\n","            optimizer.zero_grad() \n","            model.hidden_cell = (\n","                torch.zeros(1, 1, model.hidden_layer_size),\n","                torch.zeros(1, 1, model.hidden_layer_size)\n","            )\n","            # forward\n","            y_pred = model(flat_seq)\n","            # backward\n","            single_loss = model.loss(loss_function, y_pred, flat_seq_target)\n","            train_losses.append(single_loss.item())\n","            single_loss.backward()\n","            # and step :)\n","            optimizer.step()\n","            if batch_idx % training_print_interval == 0:\n","                print(f'  {batch_idx:5} : {np.mean(train_losses):10.8f}')\n","        if i%epoch_print_interval == 0:\n","            print(f'epoch: {i:3} train loss: {np.mean(train_losses):10.8f}')\n","        # evaluate the test performance\n","        model.eval()\n","        test_losses = []\n","        with torch.no_grad():\n","            for batch_idx, (seq, seq_target) in enumerate(test_loader):\n","                flat_seq = seq.permute(1,2,3,0).view(mnist_seq_length,-1).float()\n","                flat_seq_target = seq_target[:, 0, :, :].view(1,-1).float()\n","                model.hidden_cell = (\n","                    torch.zeros(1, 1, model.hidden_layer_size),\n","                    torch.zeros(1, 1, model.hidden_layer_size)\n","                )\n","                y_pred = model(flat_seq)\n","                single_loss = model.loss(loss_function, y_pred, flat_seq_target)\n","                test_losses.append(single_loss.item())\n","        if i%epoch_print_interval == 0:\n","            print(f'epoch: {i:3}  test loss: {np.mean(test_losses):10.8f}')\n","    \n","    # now save the model we have\n","    if end_save_path is not None:\n","        model.save_model(end_save_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNv5gapbjty7"},"source":["from matplotlib.animation import FuncAnimation\n","\n","def generate_pred_animations(img_dim, ckpt_path, anim_length, anim_path):\n","    data_size = img_dim*img_dim\n","    model = LSTM(input_size=data_size, output_size=data_size)\n","    model.load_model(ckpt_path)\n","\n","    # generate the predictions from the first training set datapoint\n","    model.eval()\n","    fut_pred = anim_length\n","    for seq, seq_target in list(test_loader):\n","        # get the seed sequence\n","        flat_seq = seq.permute(1,2,3,0).view(mnist_seq_length,-1).float()\n","        test_inputs = flat_seq.tolist()\n","\n","        # make following predictions\n","        for i in range(fut_pred):\n","            seq = torch.as_tensor(test_inputs[-mnist_seq_length:])\n","            with torch.no_grad():\n","                model.hidden = (\n","                    torch.zeros(1, 1, model.hidden_layer_size),\n","                    torch.zeros(1, 1, model.hidden_layer_size)\n","                )\n","                test_inputs.append(model(seq).view(data_size).tolist())\n","        break\n","\n","    # Reference point https://brushingupscience.com/2016/06/21/matplotlib-animations-the-easy-way/\n","    # write the predicted output into an actual file now...\n","\n","    # create list of tensors representing frames to be animated\n","    test_input_preview = torch.as_tensor(test_inputs[:anim_length])\n","    fig, ax = plt.subplots(figsize=(5, 3))\n","\n","    # function to update animation frames\n","    def animate(i):\n","        ax.set_title('Frame ' + str(i))\n","        ax.imshow(test_input_preview[i, :].view(img_dim,img_dim), interpolation='nearest')\n","\n","    anim = FuncAnimation(\n","        fig, animate, interval=150, frames=anim_length)\n","    \n","    plt.draw()\n","    plt.show()\n","\n","    anim.save(anim_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8H0ZW68OzZuY"},"source":["train_model(data_size=64*64, epochs=10, start_save_path=None, end_save_path=BASE_PATH+'10e_saved_model.pt')\n","!cp 10e_saved_model.pt 10e_saved.ckpt\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'10e_saved.ckpt', anim_length=20, anim_path=BASE_PATH+'10e_preds_quick.mp4')\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'10e_saved.ckpt', anim_length=60, anim_path=BASE_PATH+'10e_preds_long.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aRmEuoJ9R_K"},"source":["train_model(data_size=64*64, epochs=10, start_save_path=BASE_PATH+'10e_saved_model.pt', end_save_path=BASE_PATH+'20e_saved_model.pt')\n","!cp 20e_saved_model.pt 20e_saved.ckpt\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'20e_saved.ckpt', anim_length=20, anim_path=BASE_PATH+'20e_preds_quick.mp4')\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'20e_saved.ckpt', anim_length=60, anim_path=BASE_PATH+'20e_preds_long.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IM_jQ6qIOojg"},"source":["train_model(data_size=64*64, epochs=10, start_save_path=BASE_PATH+'20e_saved_model.pt', end_save_path=BASE_PATH+'30e_saved_model.pt')\n","!cp 30e_saved_model.pt 30e_saved.ckpt\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'30e_saved.ckpt', anim_length=20, anim_path=BASE_PATH+'30e_preds_quick.mp4')\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'30e_saved.ckpt', anim_length=60, anim_path=BASE_PATH+'30e_preds_long.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mF2v7NmUO2a7"},"source":["train_model(data_size=64*64, epochs=10, start_save_path=BASE_PATH+'30e_saved_model.pt', end_save_path=BASE_PATH+'40e_saved_model.pt')\n","!cp 40e_saved_model.pt 40e_saved.ckpt\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'40e_saved.ckpt', anim_length=20, anim_path=BASE_PATH+'40e_preds_quick.mp4')\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'40e_saved.ckpt', anim_length=60, anim_path=BASE_PATH+'40e_preds_long.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkzeTT2CO68x"},"source":["train_model(data_size=64*64, epochs=10, start_save_path=BASE_PATH+'40e_saved_model.pt', end_save_path=BASE_PATH+'50e_saved_model.pt')\n","!cp 50e_saved_model.pt 50e_saved.ckpt\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'50e_saved.ckpt', anim_length=20, anim_path=BASE_PATH+'50e_preds_quick.mp4')\n","generate_pred_animations(img_dim=64, ckpt_path=BASE_PATH+'50e_saved.ckpt', anim_length=60, anim_path=BASE_PATH+'50e_preds_long.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT0TOKcn8ZZM"},"source":["import sys, os\n","\n","def eval_model(data_size, save_path):\n","    # initialize the model we will be evaluating!\n","    model = LSTM(input_size=data_size, output_size=data_size)\n","    model.load_model(save_path)\n","    loss_function = nn.MSELoss()\n","\n","    # evaluate the test performance\n","    model.eval()\n","    test_losses = []\n","    with torch.no_grad():\n","        for batch_idx, (seq, seq_target) in enumerate(test_loader):\n","            flat_seq = seq.permute(1,2,3,0).view(mnist_seq_length,-1).float()\n","            flat_seq_target = seq_target[:, 0, :, :].view(1,-1).float()\n","            model.hidden_cell = (\n","                torch.zeros(1, 1, model.hidden_layer_size),\n","                torch.zeros(1, 1, model.hidden_layer_size)\n","            )\n","            y_pred = model(flat_seq)\n","            single_loss = model.loss(loss_function, y_pred, flat_seq_target)\n","            test_losses.append(single_loss.item())\n","    print(f'model at {save_path} ...')\n","    print(f'         test loss: {np.mean(test_losses):10.8f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywvehYJ48lzY"},"source":["eval_model(data_size=64*64, save_path=BASE_PATH+'10e_saved.ckpt')\n","eval_model(data_size=64*64, save_path=BASE_PATH+'20e_saved.ckpt')\n","eval_model(data_size=64*64, save_path=BASE_PATH+'30e_saved.ckpt')\n","eval_model(data_size=64*64, save_path=BASE_PATH+'40e_saved.ckpt')\n","eval_model(data_size=64*64, save_path=BASE_PATH+'50e_saved.ckpt')"],"execution_count":null,"outputs":[]}]}
